# SASES: Smart Answer Sheet Alignment and Evaluation System

A comprehensive multi-agent AI system for automated evaluation of handwritten exam answer sheets with advanced image processing, OCR, and intelligent grading capabilities.

## ğŸ¯ System Overview

SASES is a production-ready exam evaluation platform that processes scanned answer sheets through a complete pipeline:

1. **Image Alignment** â†’ OpenCV-based deskewing and perspective correction
2. **OCR Processing** â†’ Qwen2-VL model for handwritten text extraction
3. **Answer Parsing** â†’ Structured question-answer extraction
4. **AI Evaluation** â†’ Mistral LLM-powered grading with detailed feedback
5. **Results Analytics** â†’ Comprehensive scoring and performance insights

## âœ¨ Key Features

### ğŸ” Advanced Image Processing
- **Automatic Alignment**: OpenCV-powered deskewing and perspective correction
- **Multi-format Support**: PDF, DOCX, and image file processing
- **Quality Enhancement**: Gaussian blur, edge detection, and contour analysis

### ğŸ¤– AI-Powered OCR & Evaluation
- **Qwen2-VL Integration**: State-of-the-art vision-language model for OCR
- **Mistral LLM Grading**: Intelligent evaluation with detailed feedback
- **Fallback Mechanisms**: Robust error handling and alternative processing paths

### ğŸ“Š Comprehensive Analytics
- **Real-time Processing**: Async pipeline with GPU memory management
- **Structured Data Storage**: MongoDB-backed results with full audit trail
- **Performance Metrics**: Detailed scoring, percentage calculations, and analytics

### ğŸŒ Modern Web Interface
- **React Frontend**: Intuitive file upload and results visualization
- **FastAPI Backend**: High-performance async API with automatic documentation
- **Responsive Design**: Tailwind CSS with Framer Motion animations

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React UI      â”‚    â”‚   FastAPI       â”‚    â”‚   MongoDB       â”‚
â”‚   (Upload)      â”‚â—„â”€â”€â–ºâ”‚   Backend       â”‚â—„â”€â”€â–ºâ”‚   Database      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Alignment Agent â”‚â”€â”€â”€â–ºâ”‚   OCR Agent     â”‚â”€â”€â”€â–ºâ”‚ Parser Agent    â”‚
â”‚ (OpenCV)        â”‚    â”‚ (Qwen2-VL)      â”‚    â”‚ (Regex/LLM)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Evaluation      â”‚â”€â”€â”€â–ºâ”‚ Result Agent    â”‚â”€â”€â”€â–ºâ”‚ Analytics       â”‚
â”‚ Agent (Mistral) â”‚    â”‚ (Mistral)       â”‚    â”‚ Dashboard       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

#### ğŸ¤– Agent System
- **Alignment Agent**: OpenCV-based image preprocessing and deskewing
- **OCR Agent**: Qwen2-VL vision-language model for handwritten text extraction
- **Parser Agent**: Intelligent question key and answer structure parsing
- **Evaluation Agent**: Mistral LLM-powered grading with rubric-based scoring
- **Result Agent**: Detailed feedback generation and performance analysis

#### ğŸ“ Data Pipeline
- **Raw Data Storage**: `raw_things/` folder with complete processing audit trail
- **Processed Images**: `processed_images/` with aligned and enhanced versions
- **Structured Results**: JSON-formatted evaluation data with full metadata

## ğŸš€ Current Status

### âœ… Completed Features
- **Image Alignment**: Full OpenCV pipeline with perspective correction
- **OCR Processing**: Qwen2-VL integration with GPU acceleration
- **Multi-Agent Pipeline**: Complete async processing workflow
- **Database Integration**: MongoDB with Motor for async operations
- **Frontend Interface**: React-based upload and results visualization
- **Real Data Processing**: 100+ processed exam files with actual OCR results

### âŒ Issues & Incomplete Features

#### ğŸ”´ Critical Issues
1. **MCP Server Missing**: Despite documentation claims, no MCP server exists
   - Agents currently use Ollama directly instead of centralized MCP management
   - Need to implement FastAPI-based MCP server for model abstraction

2. **OCR Agent Dependency Issues**: Qwen2-VL model loading problems
   - Currently operating in fallback mode for demo purposes
   - Real OCR processing works but model initialization fails

3. **Direct LLM Dependencies**: Agents bypass MCP layer
   - `evaluation_agent_mistral.py` and `result_agent.py` use Ollama directly
   - No centralized model management or load balancing

#### ğŸŸ¡ Missing Features
1. **MCP Integration**: Implement centralized LLM management server
2. **Model Health Monitoring**: GPU memory management and model lifecycle
3. **Batch Processing**: Multi-file evaluation capabilities
4. **Enhanced Analytics**: Detailed performance dashboards and trends
5. **Error Recovery**: Improved fallback mechanisms and retry logic

## ğŸ“‹ Setup & Installation

### Prerequisites
- Python 3.8+
- Node.js 16+
- MongoDB 4.4+
- Ollama (for Mistral model)
- CUDA-compatible GPU (recommended for OCR)

### Backend Setup

1. **Environment Setup**:
   ```bash
   cd backend
   python -m venv venv
   venv\Scripts\activate  # Windows
   pip install -r requirements.txt
   ```

2. **Database Setup**:
   ```bash
   # Start MongoDB service
   mongod --dbpath /path/to/db
   ```

3. **Model Setup**:
   ```bash
   # Install Ollama and pull Mistral
   ollama pull mistral

   # For OCR (Qwen2-VL), models are downloaded automatically
   ```

4. **Start Backend**:
   ```bash
   uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
   ```

### Frontend Setup

1. **Install Dependencies**:
   ```bash
   cd frontend
   npm install
   ```

2. **Start Development Server**:
   ```bash
   npm run dev
   ```

3. **Build for Production**:
   ```bash
   npm run build
   npm run preview
   ```

## ğŸ”§ Configuration

### Environment Variables
```bash
# Database
MONGODB_URL=mongodb://localhost:27017/sases

# Model Settings
OLLAMA_BASE_URL=http://localhost:11434
QWEN_MODEL=Qwen/Qwen2-VL-2B-Instruct

# Processing
MAX_FILE_SIZE=50MB
GPU_MEMORY_LIMIT=8GB
```

### Model Configuration
- **OCR**: Qwen2-VL-2B-Instruct (automatic download)
- **Evaluation**: Mistral 7B via Ollama
- **Feedback**: Mistral 7B via Ollama

## ğŸ“Š API Documentation

### Core Endpoints

#### File Upload
```http
POST /upload/answer_sheet
POST /upload/question_key
Content-Type: multipart/form-data

Response: {"file_id": "uuid", "message": "success"}
```

#### Processing Pipeline
```http
POST /process
Content-Type: application/x-www-form-urlencoded

Body:
- answer_sheet_id: string
- question_key_id: string
- student_name: string (optional)
- subject: string (optional)

Response: {
  "subject": "Physics",
  "student_answers": {...},
  "evaluation": {...},
  "total_score": 85.5,
  "max_score": 100,
  "percentage": 85.5,
  "status": "success"
}
```

#### Results Retrieval
```http
GET /results/{submission_id}

Response: {
  "submission": {...},
  "answers": {...},
  "evaluation": {...}
}
```

## ğŸ“ Project Structure

```
sases/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ agents/              # AI agent implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ alignment_agent.py    # OpenCV image processing
â”‚   â”‚   â”‚   â”œâ”€â”€ ocr_agent_qwen.py     # Qwen2-VL OCR engine
â”‚   â”‚   â”‚   â”œâ”€â”€ parser_agent.py       # Question/answer parsing
â”‚   â”‚   â”‚   â”œâ”€â”€ evaluation_agent_mistral.py  # AI grading
â”‚   â”‚   â”‚   â””â”€â”€ result_agent.py       # Feedback generation
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ schemas.py           # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”œâ”€â”€ file_utils.py        # File handling utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ text_utils.py        # Text processing helpers
â”‚   â”‚   â”‚   â””â”€â”€ logger.py            # Logging configuration
â”‚   â”‚   â”œâ”€â”€ database.py              # MongoDB connection
â”‚   â”‚   â”œâ”€â”€ main.py                  # FastAPI application
â”‚   â”‚   â””â”€â”€ orchestrator.py          # Agent coordination
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ uploads/                     # Temporary file storage
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/              # React components
â”‚   â”‚   â”œâ”€â”€ App.jsx                  # Main application
â”‚   â”‚   â””â”€â”€ main.jsx                 # React entry point
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tailwind.config.js
â”œâ”€â”€ processed_images/                 # Aligned image outputs
â”œâ”€â”€ raw_things/                       # Raw processing data (100+ files)
â”œâ”€â”€ correct_ocr/                      # OCR validation outputs
â”œâ”€â”€ sample_images/                    # Test data
â””â”€â”€ README.md
```

## ğŸ¯ Usage Examples

### Single File Processing
```python
from backend.app.orchestrator import Orchestrator

orchestrator = Orchestrator()
result = await orchestrator.process_submission(
    answer_sheet_path="exam.pdf",
    question_key_path="questions.docx"
)
print(f"Score: {result['total_score']}/{result['max_score']}")
```

### OCR Testing
```bash
cd backend
python test_ocr_only.py
```

## ğŸ”„ Development Roadmap

### Phase 1: MCP Integration (High Priority)
- [ ] Implement FastAPI-based MCP server
- [ ] Update all agents to use MCP instead of direct Ollama calls
- [ ] Add model health monitoring and load balancing
- [ ] Implement centralized configuration management

### Phase 2: OCR Improvements (High Priority)
- [ ] Fix Qwen2-VL model loading issues
- [ ] Implement proper GPU memory management
- [ ] Add OCR confidence scoring
- [ ] Enhance fallback mechanisms

### Phase 3: Enhanced Features (Medium Priority)
- [ ] Batch processing capabilities
- [ ] Advanced analytics dashboard
- [ ] Real-time processing status
- [ ] Export functionality (PDF reports)

### Phase 4: Production Readiness (Low Priority)
- [ ] Docker containerization
- [ ] Kubernetes deployment manifests
- [ ] Monitoring and logging improvements
- [ ] Security hardening

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Implement changes with comprehensive tests
4. Update documentation
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **Qwen2-VL**: Alibaba Cloud's advanced vision-language model
- **Mistral AI**: High-performance open-source LLM
- **OpenCV**: Computer vision library for image processing
- **FastAPI**: Modern Python web framework
- **React**: Frontend library for user interfaces

---

**Note**: This system has successfully processed 100+ real exam files with actual OCR, alignment, and AI evaluation capabilities. The MCP integration and OCR improvements are the primary focus for production deployment.